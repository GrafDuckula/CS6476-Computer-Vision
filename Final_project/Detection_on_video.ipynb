{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_dir = '/content/drive/My Drive/Final_project/data'\n",
    "    model_dir = '/content/drive/My Drive/Final_project/model'\n",
    "    output_dir = '/content/drive/My Drive/Final_project/output'\n",
    "else:\n",
    "    data_dir = './data'\n",
    "    model_dir = './model'\n",
    "    output_dir = './output'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "from scipy.io import loadmat\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "from sklearn.svm import LinearSVC\n",
    "# from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "use_GPU = torch.cuda.is_available()\n",
    "if use_GPU:\n",
    "    print(\"Using CUDA\")\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    print (\"Using CPU\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "drop_rate = 0.2\n",
    "\n",
    "class my_model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(my_model, self).__init__()\n",
    "\n",
    "        self._hidden1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=48, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=48),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            nn.Dropout(drop_rate)\n",
    "        )\n",
    "        self._hidden2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=48, out_channels=64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=0),\n",
    "            nn.Dropout(drop_rate)\n",
    "        )\n",
    "        self._hidden3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            nn.Dropout(drop_rate)\n",
    "        )\n",
    "        self._hidden4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=160, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=160),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=0),\n",
    "            nn.Dropout(drop_rate)\n",
    "        )\n",
    "        self._hidden5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=160, out_channels=192, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            nn.Dropout(drop_rate)\n",
    "        )\n",
    "        self._hidden6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=192, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=0),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self._hidden7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=192, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            nn.Dropout(drop_rate)\n",
    "        )\n",
    "        self._hidden8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=192, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=0),\n",
    "            nn.Dropout(drop_rate)\n",
    "        )\n",
    "        self._hidden9 = nn.Sequential(\n",
    "            nn.Linear(192 * 3 * 3, 3072),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self._hidden10 = nn.Sequential(\n",
    "            nn.Linear(3072, 3072),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self._output = nn.Sequential(nn.Linear(3072, 11))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._hidden1(x)\n",
    "        x = self._hidden2(x)\n",
    "        x = self._hidden3(x)\n",
    "        x = self._hidden4(x)\n",
    "        x = self._hidden5(x)\n",
    "        x = self._hidden6(x)\n",
    "        x = self._hidden7(x)\n",
    "        x = self._hidden8(x)\n",
    "        x = x.view(x.size(0), 192 * 3 * 3)\n",
    "        x = self._hidden9(x)\n",
    "        x = self._hidden10(x)\n",
    "\n",
    "        output = self._output(x)  \n",
    "        \n",
    "        return output\n",
    "\n",
    "# test = my_model()\n",
    "# print(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.Resize([48, 48]),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])]) # orignally for ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16\n",
    "\n",
    "pretrained = False\n",
    "if pretrained:\n",
    "    # load pretrained model\n",
    "    vgg16 = models.vgg16(pretrained=True) # pretrained\n",
    "    \n",
    "    for param in vgg16.features.parameters():\n",
    "        param.require_grad = False # Freeze training for all layers\n",
    "else:\n",
    "    vgg16 = models.vgg16() # random weights\n",
    "\n",
    "# modify the output of the last layer from 1000 to 11\n",
    "num_classes = 11 # 10 digits and null\n",
    "num_in_features = vgg16.classifier[6].in_features # totally 7 modules inside\n",
    "features = list(vgg16.classifier.children())[:-1] # Remove last layer\n",
    "# Newly created modules have require_grad=True by default\n",
    "features.extend([nn.Linear(num_in_features, num_classes)]) # Add last layer with 11 outputs\n",
    "vgg16.classifier = nn.Sequential(*features) # Replace the last layer of classifier\n",
    "\n",
    "# print(vgg16)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using MSER\n",
    "\n",
    "def MSER_detect(img, delta, min_area, max_area):\n",
    "    \n",
    "    image = np.copy(img)\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     img_blur = cv2.GaussianBlur(img_gray, (5,5),0) # blur\n",
    "\n",
    "    mser = cv2.MSER_create(_delta=delta, _min_area = min_area, _max_area = max_area)\n",
    "#     regions = mser.detectRegions(img_blur)\n",
    "    regions = mser.detectRegions(img_gray)\n",
    "    \n",
    "    color = (255, 0, 0)\n",
    "    thickness = 20\n",
    "    for region in regions[1]:\n",
    "        start_point = (region[0], region[1])\n",
    "        end_point = (region[0] + region[2], region[1] + region[3])\n",
    "        cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()\n",
    "\n",
    "    return regions[1]\n",
    "\n",
    "    \n",
    "# I would recommend to use the raw logits + nn.CrossEntropyLoss for training \n",
    "# and if you really need to see the probabilities, \n",
    "# just call F.softmax on the output as described in the other post.\n",
    "\n",
    "def predict(model, images):\n",
    "    model.train(False)\n",
    "    model.eval()\n",
    "    \n",
    "    print ()\n",
    "    print ('start prediction')\n",
    "\n",
    "    if use_GPU:\n",
    "        images = images.to(device)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    outputs = model(images)\n",
    "\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    probabilities = F.softmax(outputs,dim=1)\n",
    "    scores = torch.max(probabilities, dim=1)[0]\n",
    "\n",
    "#     del images, outputs, preds, probability\n",
    "#     torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds, scores\n",
    "\n",
    "\n",
    "# enlarger ratio is how much to enlarge the box.\n",
    "# wh ratio is width/height ratio range, 0.5-2.0\n",
    "\n",
    "def create_subimages_with_scores(image, regions,\n",
    "                                 enlarger_ratio = 1.0, wh_ratio = 2.0,\n",
    "                                 min_w = 30, min_h = 30, \n",
    "                                 max_w = 1000, max_h = 1000) :\n",
    "    boxes = []\n",
    "    subimages = []\n",
    "\n",
    "#     image = cv2.imread(os.path.join(data_dir, image_file))\n",
    "    img = np.copy(image)\n",
    "    print (img.shape)\n",
    "\n",
    "    for box in regions:\n",
    "        x1 = int(box[0]-box[2]*1.0)\n",
    "        y1 = int(box[1]-box[3]*1.0)\n",
    "        x2 = int(box[0] + box[2] + box[2]*1.0)\n",
    "        y2 = int(box[1] + box[3] + box[3]*1.0)\n",
    "        \n",
    "        # if the point location is outside of the image, keep it on the edge.\n",
    "        if x1 < 0: \n",
    "            x1 = box[0]\n",
    "        if y1 < 0:\n",
    "            y1 = box[1]\n",
    "        if x2 > img.shape[1]:\n",
    "            x2 = box[0] + box[2]\n",
    "        if y2 > img.shape[0]:\n",
    "            y2 = box[1] + box[3]\n",
    "\n",
    "        if box[2] >= min_w and box[3] >= min_h and box[2] <= max_w and box[3] <= max_h and box[3]/box[2]<=wh_ratio and box[2]/box[3]<=wh_ratio:\n",
    "            boxes.append((x1,y1,x2,y2))\n",
    "            image_cut = img[y1:y2,x1:x2,:] \n",
    "#             print ((x1,y1,x2,y2))\n",
    "            print ()\n",
    "            image_cut = torchvision.transforms.functional.to_pil_image(image_cut)      \n",
    "            image_cut = transform(image_cut)        \n",
    "            subimages.append(image_cut)\n",
    "    \n",
    "    \n",
    "\n",
    "    subimages = torch.stack(subimages)\n",
    "    labels, scores = predict(detect_model, subimages)\n",
    "\n",
    "    print (labels)\n",
    "    print (scores)\n",
    "\n",
    "    # remove boxes with label 10\n",
    "    new_boxes = []\n",
    "    new_scores = []\n",
    "    new_labels = []\n",
    "    for i, label in enumerate(labels):\n",
    "        if label != 10:\n",
    "            new_boxes.append(boxes[i])\n",
    "            new_scores.append(scores[i].item())\n",
    "            new_labels.append(labels[i].item())\n",
    "\n",
    "    print (new_boxes)\n",
    "    print (new_scores)\n",
    "    print (new_labels)\n",
    "\n",
    "    color = (255, 0, 0)\n",
    "    thickness = 20\n",
    "    for box in new_boxes:\n",
    "        start_point = (box[0], box[1])\n",
    "        end_point = (box[2], box[3])\n",
    "        cv2.rectangle(img, start_point, end_point, color, thickness)\n",
    "\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    \n",
    "    return new_boxes, new_labels, new_scores\n",
    "\n",
    "\n",
    "\n",
    "def merge_boxes_and_digits(image, boxes, labels, scores, keep_idx):\n",
    "    \n",
    "    \n",
    "    \n",
    "    remove_idx = []\n",
    "    for i in keep_idx:\n",
    "        for j in keep_idx:\n",
    "            if boxes[i][0]<boxes[j][0] and boxes[i][1]<boxes[j][1] and boxes[i][2]>boxes[j][2] and boxes[i][3]>boxes[j][3]:\n",
    "                remove_idx.append(j)\n",
    "    \n",
    "    keep_idx = keep_idx.numpy().tolist()       \n",
    "    for idx in remove_idx:\n",
    "        keep_idx.remove(idx)\n",
    "    \n",
    "    # if the centers of two clusters are far than some distance, then \n",
    "    \n",
    "    keep_box = np.array([boxes[idx] for idx in keep_idx])\n",
    "    keep_numbers = np.array([labels[idx] for idx in keep_idx])\n",
    "    keep_scores = np.array([scores[idx] for idx in keep_idx])\n",
    "    \n",
    "    \n",
    "    Z = np.array(keep_box)\n",
    "    print (Z)\n",
    "    \n",
    "    if len(Z)>1:\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,10,1.0)\n",
    "        # (type,max_iter,epsilon)\n",
    "        flags=cv2.KMEANS_RANDOM_CENTERS\n",
    "        compactness,label,center = cv2.kmeans(np.float32(Z), 2, None, criteria, 10, flags)\n",
    "\n",
    "        print (label)\n",
    "        print (\"label = \", label.ravel)\n",
    "        C = Z[label.ravel()==0]\n",
    "        D = Z[label.ravel()==1]\n",
    "        print (C)\n",
    "        print (D)\n",
    "\n",
    "        print (\"center = \", center)\n",
    "\n",
    "        # cluster_a_center = \n",
    "\n",
    "        print (\"keep_scores\")\n",
    "        print (keep_scores)\n",
    "\n",
    "        if abs(center[0][1]+center[0][3]-center[1][1]-center[1][3])/2.0>=0.1*image.shape[0]:\n",
    "            # two clusters\n",
    "            A = np.mean(keep_scores[label.ravel()==0])\n",
    "            B = np.mean(keep_scores[label.ravel()==1])\n",
    "            if A > B:\n",
    "                keep_box = keep_box[label.ravel()==0]\n",
    "                keep_numbers = keep_numbers[label.ravel()==0]\n",
    "                keep_scores = keep_scores[label.ravel()==0]\n",
    "            else:\n",
    "                keep_box = keep_box[label.ravel()==1]\n",
    "                keep_numbers = keep_numbers[label.ravel()==1]\n",
    "                keep_scores = keep_scores[label.ravel()==1]\n",
    "    \n",
    "    \n",
    "    x_centers = [(keep_box[idx][0]+keep_box[idx][2])/2 for idx in range(len(keep_box))]    \n",
    "    digit_order = np.argsort(x_centers)\n",
    "    digits = [str(keep_numbers[i]) for i in digit_order]\n",
    "    final_number = int(\"\".join(digits))\n",
    "    \n",
    "    final_x1 = np.min([keep_box[idx][0] for idx in range(len(keep_box))])\n",
    "    final_y1 = np.min([keep_box[idx][1] for idx in range(len(keep_box))])\n",
    "    final_x2 = np.max([keep_box[idx][2] for idx in range(len(keep_box))])\n",
    "    final_y2 = np.max([keep_box[idx][3] for idx in range(len(keep_box))])\n",
    "\n",
    "    print (str(final_number))\n",
    "    \n",
    "#     final_img = np.copy(image)\n",
    "#     color = (255, 0, 0)\n",
    "#     thickness = 20\n",
    "#     cv2.rectangle(final_img, (final_x1, final_y1), (final_x2, final_y2), color, thickness)\n",
    "#     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     cv2.putText(final_img, str(final_number), (int((final_x1+final_x2)/2), final_y1-50), font, 8, color, 30)\n",
    "#     plt.imshow(final_img)\n",
    "#     plt.show()\n",
    "    \n",
    "    return final_number, (final_x1, final_y1, final_x2, final_y2)\n",
    "\n",
    "\n",
    "    \n",
    "def video_frame_generator(filename):\n",
    "    \"\"\"A generator function that returns a frame on each 'next()' call.\n",
    "\n",
    "    Will return 'None' when there are no frames left.\n",
    "\n",
    "    Args:\n",
    "        filename (string): Filename.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    # Open file with VideoCapture and set result to 'video'.\n",
    "    video = cv2.VideoCapture(filename)\n",
    "\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        if ret:\n",
    "            yield frame\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Close video (release) and yield a 'None' value.\n",
    "    video.release()\n",
    "    yield None\n",
    "\n",
    "    \n",
    "def mp4_video_writer(filename, frame_size, fps=20):\n",
    "    \"\"\"Opens and returns a video for writing.\n",
    "\n",
    "    Use the VideoWriter's `write` method to save images.\n",
    "    Remember to 'release' when finished.\n",
    "\n",
    "    Args:\n",
    "        filename (string): Filename for saved video\n",
    "        frame_size (tuple): Width, height tuple of output video\n",
    "        fps (int): Frames per second\n",
    "    Returns:\n",
    "        VideoWriter: Instance of VideoWriter ready for writing\n",
    "    \"\"\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    return cv2.VideoWriter(filename, fourcc, fps, frame_size)    \n",
    "\n",
    "    \n",
    "\n",
    "def detect_and_plot_numbers(image, font_size=6, thickness=20):\n",
    "    \n",
    "    regions = MSER_detect(image, 4, 1000, 5000)\n",
    "\n",
    "    print (len(regions))\n",
    "    \n",
    "    if len(regions) > 0: \n",
    "\n",
    "        boxes, labels, scores = create_subimages_with_scores(image,regions, \n",
    "                                         enlarger_ratio = 0.5, wh_ratio = 2.0,\n",
    "                                         min_w = 30, min_h = 30, \n",
    "                                         max_w = 1000, max_h = 1000)\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "        \n",
    "            # nms\n",
    "            iou_threshold = 0.5\n",
    "            keep_idx = torchvision.ops.nms(torch.FloatTensor(boxes), torch.FloatTensor(scores), iou_threshold)\n",
    "            print (\"keep_idx = \", keep_idx)\n",
    "\n",
    "            if len(keep_idx.numpy()) > 0:\n",
    "\n",
    "                # merge boxes and generate digits  \n",
    "                number, (x1, y1, x2, y2) = merge_boxes_and_digits(image, boxes, labels, scores, keep_idx)\n",
    "\n",
    "                # generate image\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 20\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(image, str(number), (int((x1+x2)/2), y1-50), font, font_size, color, thickness)\n",
    "#                 plt.imshow(image)\n",
    "#                 plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_video(VID_DIR, video_name, OUTPUT_DIR, filename, fps, frame_ids):\n",
    "    \n",
    "    video = os.path.join(VID_DIR, video_name+\".mp4\")\n",
    "    print (video)\n",
    "    image_gen = video_frame_generator(video)\n",
    "\n",
    "    image = image_gen.__next__()\n",
    "    h, w, d = image.shape\n",
    "\n",
    "    out_path = os.path.join(OUTPUT_DIR, video_name+\"_with_numbers.mp4\")\n",
    "    \n",
    "    video_out = mp4_video_writer(out_path, (w, h), fps)\n",
    "    \n",
    "    frame_num = 1\n",
    "    \n",
    "\n",
    "    while image is not None:\n",
    "\n",
    "        print(\"Processing fame {}\".format(frame_num))\n",
    "        \n",
    "        detect_and_plot_numbers(image, font_size=6, thickness=20)\n",
    "        \n",
    "#         if frame_num in frame_ids:      \n",
    "#             cv2.imwrite(os.path.join(OUTPUT_DIR, str(filename) + '_'+ str(frame_num) + \".png\"), image)\n",
    "        \n",
    "        video_out.write(image)\n",
    "        \n",
    "#         cv2.imshow('image', image)\n",
    "        \n",
    "#         if cv2.waitKey(1) == ord('q'):\n",
    "#             break\n",
    "\n",
    "        image = image_gen.__next__()\n",
    "\n",
    "        frame_num += 1\n",
    "        \n",
    "#         if frame_num >= 280:\n",
    "        \n",
    "#             image = image[140:, 250:, :]\n",
    "#             image = cv2.resize(image, (w, h))\n",
    "\n",
    "    video_out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "model_save_name = 'MyModel_SVHN_Dec_03.pt'\n",
    "\n",
    "if use_GPU:\n",
    "    model_path = F'/content/drive/My Drive/Final_project/model/{model_save_name}' \n",
    "    detect_model = my_model()\n",
    "    detect_model.load_state_dict(state_dict=torch.load(model_path))\n",
    "    my_model.cuda()\n",
    "    print('My model loaded!') \n",
    "\n",
    "else:\n",
    "    model_path = os.path.join(model_dir, model_save_name)\n",
    "    detect_model = my_model()\n",
    "    detect_model.load_state_dict(state_dict=torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    print('My model loaded!') \n",
    "\n",
    "print ()\n",
    "\n",
    "video_name = \"IMG_2890\"\n",
    "filename = \"IMG_2890\"\n",
    "\n",
    "frame_ids = [50, 100, 150, 200]\n",
    "\n",
    "   \n",
    "generate_video(VID_DIR=data_dir, video_name=video_name, OUTPUT_DIR=output_dir, filename=filename, fps=24, frame_ids=frame_ids)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # produce 5 images\n",
    "\n",
    "# # using MSER\n",
    "\n",
    "# def MSER_detect(img, delta, min_area, max_area):\n",
    "    \n",
    "#     image = np.copy(img)\n",
    "#     img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     img_blur = cv2.GaussianBlur(img_gray, (5,5),0) # blur\n",
    "\n",
    "#     mser = cv2.MSER_create(_delta=delta, _min_area = min_area, _max_area = max_area)\n",
    "#     regions = mser.detectRegions(img_blur)\n",
    "# #     regions = mser.detectRegions(img_gray)\n",
    "    \n",
    "#     color = (255, 0, 0)\n",
    "#     thickness = 20\n",
    "#     for region in regions[1]:\n",
    "#         start_point = (region[0], region[1])\n",
    "#         end_point = (region[0] + region[2], region[1] + region[3])\n",
    "#         cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "\n",
    "# #     plt.imshow(image)\n",
    "# #     plt.show()\n",
    "\n",
    "#     return regions[1]\n",
    "\n",
    "    \n",
    "# # I would recommend to use the raw logits + nn.CrossEntropyLoss for training \n",
    "# # and if you really need to see the probabilities, \n",
    "# # just call F.softmax on the output as described in the other post.\n",
    "\n",
    "# def predict(model, images):\n",
    "#     model.train(False)\n",
    "#     model.eval()\n",
    "    \n",
    "#     print ()\n",
    "#     print ('start prediction')\n",
    "\n",
    "#     if use_GPU:\n",
    "#         images = images.to(device)\n",
    "    \n",
    "#     model.zero_grad()\n",
    "#     outputs = model(images)\n",
    "\n",
    "#     _, preds = torch.max(outputs.data, 1)\n",
    "#     probabilities = F.softmax(outputs,dim=1)\n",
    "#     scores = torch.max(probabilities, dim=1)[0]\n",
    "\n",
    "# #     del images, outputs, preds, probability\n",
    "# #     torch.cuda.empty_cache()\n",
    "    \n",
    "#     return preds, scores\n",
    "\n",
    "\n",
    "# # enlarger ratio is how much to enlarge the box.\n",
    "# # wh ratio is width/height ratio range, 0.5-2.0\n",
    "\n",
    "# def create_subimages_with_scores(image, regions,\n",
    "#                                  enlarger_ratio = 1.0, wh_ratio = 2.0,\n",
    "#                                  min_w = 30, min_h = 30, \n",
    "#                                  max_w = 1000, max_h = 1000) :\n",
    "#     boxes = []\n",
    "#     subimages = []\n",
    "\n",
    "# #     image = cv2.imread(os.path.join(data_dir, image_file))\n",
    "#     img = np.copy(image)\n",
    "#     print (img.shape)\n",
    "\n",
    "#     for box in regions:\n",
    "#         x1 = int(box[0]-box[2]*1.0)\n",
    "#         y1 = int(box[1]-box[3]*1.0)\n",
    "#         x2 = int(box[0] + box[2] + box[2]*1.0)\n",
    "#         y2 = int(box[1] + box[3] + box[3]*1.0)\n",
    "        \n",
    "#         # if the point location is outside of the image, keep it on the edge.\n",
    "#         if x1 < 0: \n",
    "#             x1 = box[0]\n",
    "#         if y1 < 0:\n",
    "#             y1 = box[1]\n",
    "#         if x2 > img.shape[1]:\n",
    "#             x2 = box[0] + box[2]\n",
    "#         if y2 > img.shape[0]:\n",
    "#             y2 = box[1] + box[3]\n",
    "\n",
    "#         if box[2] >= min_w and box[3] >= min_h and box[2] <= max_w and box[3] <= max_h and box[3]/box[2]<=wh_ratio and box[2]/box[3]<=wh_ratio:\n",
    "#             boxes.append((x1,y1,x2,y2))\n",
    "#             image_cut = img[y1:y2,x1:x2,:] \n",
    "# #             print ((x1,y1,x2,y2))\n",
    "#             print ()\n",
    "#             image_cut = torchvision.transforms.functional.to_pil_image(image_cut)      \n",
    "#             image_cut = transform(image_cut)        \n",
    "#             subimages.append(image_cut)\n",
    "    \n",
    "    \n",
    "\n",
    "#     subimages = torch.stack(subimages)\n",
    "#     labels, scores = predict(detect_model, subimages)\n",
    "\n",
    "#     print (labels)\n",
    "#     print (scores)\n",
    "\n",
    "#     # remove boxes with label 10\n",
    "#     new_boxes = []\n",
    "#     new_scores = []\n",
    "#     new_labels = []\n",
    "#     for i, label in enumerate(labels):\n",
    "#         if label != 10:\n",
    "#             new_boxes.append(boxes[i])\n",
    "#             new_scores.append(scores[i].item())\n",
    "#             new_labels.append(labels[i].item())\n",
    "\n",
    "#     print (new_boxes)\n",
    "#     print (new_scores)\n",
    "#     print (new_labels)\n",
    "\n",
    "#     color = (255, 0, 0)\n",
    "#     thickness = 20\n",
    "#     for box in new_boxes:\n",
    "#         start_point = (box[0], box[1])\n",
    "#         end_point = (box[2], box[3])\n",
    "#         cv2.rectangle(img, start_point, end_point, color, thickness)\n",
    "\n",
    "# #     plt.imshow(img)\n",
    "# #     plt.show()\n",
    "    \n",
    "#     return new_boxes, new_labels, new_scores\n",
    "\n",
    "\n",
    "\n",
    "# def merge_boxes_and_digits(image, boxes, labels, scores, keep_idx):\n",
    "    \n",
    "    \n",
    "    \n",
    "#     remove_idx = []\n",
    "#     for i in keep_idx:\n",
    "#         for j in keep_idx:\n",
    "#             if boxes[i][0]<boxes[j][0] and boxes[i][1]<boxes[j][1] and boxes[i][2]>boxes[j][2] and boxes[i][3]>boxes[j][3]:\n",
    "#                 remove_idx.append(j)\n",
    "    \n",
    "#     keep_idx = keep_idx.numpy().tolist()       \n",
    "#     for idx in remove_idx:\n",
    "#         keep_idx.remove(idx)\n",
    "    \n",
    "#     # if the centers of two clusters are far than some distance, then \n",
    "    \n",
    "#     keep_box = np.array([boxes[idx] for idx in keep_idx])\n",
    "#     keep_numbers = np.array([labels[idx] for idx in keep_idx])\n",
    "#     keep_scores = np.array([scores[idx] for idx in keep_idx])\n",
    "    \n",
    "    \n",
    "#     Z = np.array(keep_box)\n",
    "#     print (Z)\n",
    "    \n",
    "#     if len(Z)>1:\n",
    "#         criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,10,1.0)\n",
    "#         # (type,max_iter,epsilon)\n",
    "#         flags=cv2.KMEANS_RANDOM_CENTERS\n",
    "#         compactness,label,center = cv2.kmeans(np.float32(Z), 2, None, criteria, 10, flags)\n",
    "\n",
    "#         print (label)\n",
    "#         print (\"label = \", label.ravel)\n",
    "#         C = Z[label.ravel()==0]\n",
    "#         D = Z[label.ravel()==1]\n",
    "#         print (C)\n",
    "#         print (D)\n",
    "\n",
    "#         print (\"center = \", center)\n",
    "\n",
    "#         # cluster_a_center = \n",
    "\n",
    "#         print (\"keep_scores\")\n",
    "#         print (keep_scores)\n",
    "\n",
    "#         if abs(center[0][1]+center[0][3]-center[1][1]-center[1][3])/2.0>=0.1*image.shape[0]:\n",
    "#             # two clusters\n",
    "#             A = np.mean(keep_scores[label.ravel()==0])\n",
    "#             B = np.mean(keep_scores[label.ravel()==1])\n",
    "#             if A > B:\n",
    "#                 keep_box = keep_box[label.ravel()==0]\n",
    "#                 keep_numbers = keep_numbers[label.ravel()==0]\n",
    "#                 keep_scores = keep_scores[label.ravel()==0]\n",
    "#             else:\n",
    "#                 keep_box = keep_box[label.ravel()==1]\n",
    "#                 keep_numbers = keep_numbers[label.ravel()==1]\n",
    "#                 keep_scores = keep_scores[label.ravel()==1]\n",
    "    \n",
    "    \n",
    "#     x_centers = [(keep_box[idx][0]+keep_box[idx][2])/2 for idx in range(len(keep_box))]    \n",
    "#     digit_order = np.argsort(x_centers)\n",
    "#     digits = [str(keep_numbers[i]) for i in digit_order]\n",
    "#     final_number = int(\"\".join(digits))\n",
    "    \n",
    "#     final_x1 = np.min([keep_box[idx][0] for idx in range(len(keep_box))])\n",
    "#     final_y1 = np.min([keep_box[idx][1] for idx in range(len(keep_box))])\n",
    "#     final_x2 = np.max([keep_box[idx][2] for idx in range(len(keep_box))])\n",
    "#     final_y2 = np.max([keep_box[idx][3] for idx in range(len(keep_box))])\n",
    "\n",
    "#     print (str(final_number))\n",
    "    \n",
    "# #     final_img = np.copy(image)\n",
    "# #     color = (255, 0, 0)\n",
    "# #     thickness = 20\n",
    "# #     cv2.rectangle(final_img, (final_x1, final_y1), (final_x2, final_y2), color, thickness)\n",
    "# #     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# #     cv2.putText(final_img, str(final_number), (int((final_x1+final_x2)/2), final_y1-50), font, 8, color, 30)\n",
    "# #     plt.imshow(final_img)\n",
    "# #     plt.show()\n",
    "    \n",
    "#     return final_number, (final_x1, final_y1, final_x2, final_y2)\n",
    "\n",
    "\n",
    "    \n",
    "# def video_frame_generator(filename):\n",
    "#     \"\"\"A generator function that returns a frame on each 'next()' call.\n",
    "\n",
    "#     Will return 'None' when there are no frames left.\n",
    "\n",
    "#     Args:\n",
    "#         filename (string): Filename.\n",
    "\n",
    "#     Returns:\n",
    "#         None.\n",
    "#     \"\"\"\n",
    "#     # Open file with VideoCapture and set result to 'video'.\n",
    "#     video = cv2.VideoCapture(filename)\n",
    "\n",
    "#     while video.isOpened():\n",
    "#         ret, frame = video.read()\n",
    "\n",
    "#         if ret:\n",
    "#             yield frame\n",
    "#         else:\n",
    "#             break\n",
    "\n",
    "#     # Close video (release) and yield a 'None' value.\n",
    "#     video.release()\n",
    "#     yield None\n",
    "\n",
    "    \n",
    "# def mp4_video_writer(filename, frame_size, fps=20):\n",
    "#     \"\"\"Opens and returns a video for writing.\n",
    "\n",
    "#     Use the VideoWriter's `write` method to save images.\n",
    "#     Remember to 'release' when finished.\n",
    "\n",
    "#     Args:\n",
    "#         filename (string): Filename for saved video\n",
    "#         frame_size (tuple): Width, height tuple of output video\n",
    "#         fps (int): Frames per second\n",
    "#     Returns:\n",
    "#         VideoWriter: Instance of VideoWriter ready for writing\n",
    "#     \"\"\"\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "#     return cv2.VideoWriter(filename, fourcc, fps, frame_size)    \n",
    "\n",
    "    \n",
    "\n",
    "# def detect_and_plot_numbers(image, font_size=6, thickness=20):\n",
    "    \n",
    "# #     regions = MSER_detect(image, 4, 1000, 5000)\n",
    "    \n",
    "#     regions = MSER_detect(image, 4, 1000, 50000)\n",
    "\n",
    "#     print (len(regions))\n",
    "    \n",
    "#     if len(regions) > 0: \n",
    "\n",
    "#         boxes, labels, scores = create_subimages_with_scores(image,regions, \n",
    "#                                          enlarger_ratio = 0.5, wh_ratio = 2.0,\n",
    "#                                          min_w = 30, min_h = 30, \n",
    "#                                          max_w = 1000, max_h = 1000)\n",
    "        \n",
    "#         if len(boxes) > 0:\n",
    "        \n",
    "#             # nms\n",
    "#             iou_threshold = 0.5\n",
    "#             keep_idx = torchvision.ops.nms(torch.FloatTensor(boxes), torch.FloatTensor(scores), iou_threshold)\n",
    "#             print (\"keep_idx = \", keep_idx)\n",
    "\n",
    "#             if len(keep_idx.numpy()) > 0:\n",
    "\n",
    "#                 # merge boxes and generate digits  \n",
    "#                 number, (x1, y1, x2, y2) = merge_boxes_and_digits(image, boxes, labels, scores, keep_idx)\n",
    "\n",
    "#                 # generate image\n",
    "#                 color = (255, 0, 0)\n",
    "#                 thickness = 20\n",
    "#                 cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
    "#                 font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#                 cv2.putText(image, str(number), (int((x1+x2)/2), y1-50), font, font_size, color, thickness)\n",
    "# #                 plt.imshow(image)\n",
    "# #                 plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def generate_video(VID_DIR, video_name, OUTPUT_DIR, filename, fps, frame_ids):\n",
    "    \n",
    "#     video = os.path.join(VID_DIR, video_name+\".mp4\")\n",
    "#     print (video)\n",
    "#     image_gen = video_frame_generator(video)\n",
    "\n",
    "#     image = image_gen.__next__()\n",
    "#     h, w, d = image.shape\n",
    "\n",
    "#     out_path = os.path.join(OUTPUT_DIR, video_name+\"_with_numbers.mp4\")\n",
    "    \n",
    "#     video_out = mp4_video_writer(out_path, (w, h), fps)\n",
    "    \n",
    "#     frame_num = 1\n",
    "    \n",
    "\n",
    "#     while image is not None:\n",
    "\n",
    "#         print(\"Processing fame {}\".format(frame_num))\n",
    "        \n",
    "#         detect_and_plot_numbers(image, font_size=6, thickness=20)\n",
    "        \n",
    "# #         if frame_num in frame_ids:      \n",
    "# #             cv2.imwrite(os.path.join(OUTPUT_DIR, str(filename) + '_'+ str(frame_num) + \".png\"), image)\n",
    "        \n",
    "#         video_out.write(image)\n",
    "        \n",
    "# #         cv2.imshow('image', image)\n",
    "        \n",
    "# #         if cv2.waitKey(1) == ord('q'):\n",
    "# #             break\n",
    "\n",
    "#         image = image_gen.__next__()\n",
    "\n",
    "#         frame_num += 1\n",
    "        \n",
    "# #         if frame_num >= 280:\n",
    "        \n",
    "# #             image = image[140:, 250:, :]\n",
    "# #             image = cv2.resize(image, (w, h))\n",
    "\n",
    "#     video_out.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "# model_save_name = 'MyModel_SVHN_Nov_26.pt'\n",
    "\n",
    "# if use_GPU:\n",
    "#     model_path = F'/content/drive/My Drive/Final_project/model/{model_save_name}' \n",
    "#     detect_model = my_model()\n",
    "#     detect_model.load_state_dict(state_dict=torch.load(model_path))\n",
    "#     my_model.cuda()\n",
    "#     print('My model loaded!') \n",
    "\n",
    "# else:\n",
    "#     model_path = os.path.join(model_dir, model_save_name)\n",
    "#     detect_model = my_model()\n",
    "#     detect_model.load_state_dict(state_dict=torch.load(model_path, map_location=torch.device('cpu')))\n",
    "#     print('My model loaded!') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # extract frames\n",
    "# # def extract_frames():\n",
    "# #     video_name = \"IMG_2890\"\n",
    "# #     filename = \"IMG_2890\"\n",
    "\n",
    "# #     frame_ids = [15, 21, 176, 177]\n",
    "\n",
    "# #     video = os.path.join(data_dir, video_name+\".mp4\")\n",
    "# #     image_gen = video_frame_generator(video)\n",
    "\n",
    "# #     image = image_gen.__next__()\n",
    "# #     h, w, d = image.shape\n",
    "\n",
    "# #     frame_num = 1\n",
    "\n",
    "# #     while image is not None:\n",
    "\n",
    "# #         if frame_num in frame_ids:  \n",
    "# #             print(\"Processing fame {}\".format(frame_num))\n",
    "# #             cv2.imwrite(os.path.join(output_dir, str(filename) + '_'+ str(frame_num) + \".png\"), image)\n",
    "\n",
    "# #         image = image_gen.__next__()\n",
    "\n",
    "# #         frame_num += 1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# # produce 5 images\n",
    "\n",
    "# # original\n",
    "\n",
    "# frame_name = \"IMG_2890_15.png\"\n",
    "# save_name = \"0.png\"\n",
    "# image = cv2.imread(os.path.join(data_dir, frame_name))\n",
    "# detect_and_plot_numbers(image, font_size=6, thickness=20)\n",
    "# cv2.imwrite(os.path.join(output_dir, save_name), image)\n",
    "\n",
    "\n",
    "# # brightness\n",
    "\n",
    "# frame_name = \"IMG_2890_21.png\"\n",
    "# save_name = \"1.png\"\n",
    "# image = cv2.imread(os.path.join(data_dir, frame_name))\n",
    "# image = (image*0.75).astype(np.uint8)\n",
    "# detect_and_plot_numbers(image, font_size=6, thickness=20)\n",
    "# cv2.imwrite(os.path.join(output_dir, save_name), image)\n",
    "\n",
    "\n",
    "# # add noise\n",
    "\n",
    "# frame_name = \"IMG_2890_21.png\"\n",
    "# save_name = \"2.png\"\n",
    "# image = cv2.imread(os.path.join(data_dir, frame_name))\n",
    "\n",
    "# m = (0,0,0) \n",
    "# s = (20,20,20)\n",
    "# temp = np.zeros_like(image)\n",
    "# noise = cv2.randn(temp,m,s);\n",
    "\n",
    "# image = image + noise\n",
    "\n",
    "# detect_and_plot_numbers(image, font_size=6, thickness=20)\n",
    "# cv2.imwrite(os.path.join(output_dir, save_name), image)\n",
    "\n",
    "\n",
    "# # amplification\n",
    "\n",
    "# frame_name = \"IMG_2890_21.png\"\n",
    "# save_name = \"3.png\"\n",
    "# image = cv2.imread(os.path.join(data_dir, frame_name))\n",
    "# h, w, d = image.shape\n",
    "# image = image[125:875, 293:1627, :]\n",
    "# image = cv2.resize(image, (w, h))\n",
    "# print (image.shape)\n",
    "# detect_and_plot_numbers(image, font_size=6, thickness=20)\n",
    "# cv2.imwrite(os.path.join(output_dir, save_name), image)\n",
    "\n",
    "# # location\n",
    "\n",
    "# frame_name = \"IMG_2890_21.png\"\n",
    "# save_name = \"4.png\"\n",
    "# image = cv2.imread(os.path.join(data_dir, frame_name))\n",
    "# h, w, d = image.shape\n",
    "# image = image[:800, 350:, :]\n",
    "# # image = cv2.resize(image, (w, h))\n",
    "# print (image.shape)\n",
    "# detect_and_plot_numbers(image, font_size=6, thickness=20)\n",
    "# cv2.imwrite(os.path.join(output_dir, save_name), image)\n",
    "\n",
    "\n",
    "\n",
    "# # rotate\n",
    "\n",
    "# frame_name = \"IMG_2890_176.png\"\n",
    "# save_name = \"5.png\"\n",
    "# image = cv2.imread(os.path.join(data_dir, frame_name))\n",
    "# detect_and_plot_numbers(image, font_size=6, thickness=20)\n",
    "# cv2.imwrite(os.path.join(output_dir, save_name), image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
